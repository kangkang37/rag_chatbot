{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41071b75-e701-4597-9b66-8a3bcc95b8af",
   "metadata": {},
   "source": [
    "# RAG embedding adapter\n",
    " \n",
    "refer:  \n",
    "https://learn.deeplearning.ai/courses/advanced-retrieval-for-ai/lesson/6/embedding-adaptors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911dd0de-b10a-49d2-9e82-4d02c95d4b4c",
   "metadata": {},
   "source": [
    "\n",
    "The following code implements a domain-specific Q&A model based on LLM using the RAG method. The uploaded PDF file contains domain-specific knowledge, and the LLM used is the Google Gemini API.\n",
    "\n",
    "Basic functionality:\n",
    "1. First, create a vector database using chromadb.\n",
    "2. Then, upload the PDF file, use PyPDFLoader and textsplitter to read and split the file, and input the split chunks into the vector database.\n",
    "3. Call the Gemini API, input the question, search for relevant knowledge in the database, and then input the question along with the relevant knowledge to the LLM to get the answer.\n",
    "\n",
    "Additionally, query expansion and embedding adaptor methods have been implemented:\n",
    "- **Adding Embedding Adaptor**:\n",
    "  An adaptor matrix was trained to make the retrieval of relevant knowledge more accurate.\n",
    "- **Adding Query Expansion Method**:\n",
    "  For the original question, relevant questions or hypothetical answers are searched using the LLM, and then they are input into the vector database to retrieve more relevant knowledge. The knowledge and the question are then input to the LLM to get the answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15641bb1-ba06-4fb1-8e12-1cd32eab21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,SentenceTransformersTokenTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ab0bac-cf5c-4acd-9ad4-0aa7fff0cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f940ca-97fd-4236-9a19-e66d85c61938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28717d19-67c1-4af5-91fe-fc046a8af81a",
   "metadata": {},
   "source": [
    "## create collection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcfe735-8549-4064-8f2c-91c9cfa83160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chroma_client=chromadb.Client()\n",
    "\n",
    "emb_func=SentenceTransformerEmbeddingFunction()\n",
    "\n",
    "chroma_client.get_or_create_collection(name='adapter_rag01', embedding_function=emb_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8ea49b-fedc-4aa5-b293-30f12efe6238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='adapter_rag01' id=UUID('a4ea7345-b7fb-4fd7-bdd9-5fcc1f6da90a') metadata=None tenant='default_tenant' database='default_database'\n",
      "{'ids': [], 'embeddings': None, 'metadatas': [], 'documents': [], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "coll_adapter=chroma_client.get_collection(name='adapter_rag01')\n",
    "print(coll_adapter)\n",
    "print(coll_adapter.get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5f725-5b4d-4a78-b19e-4ea08310df87",
   "metadata": {},
   "source": [
    "## upload pdf and text_splitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14ca2b1-2c47-4e61-b327-dde2f2c563c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = loader.load_and_split()\n",
    "    pages_texts=[page.page_content for page in pages]\n",
    "    print(f'type of pages_texts is: {type(pages_texts)}') # <class 'list'>\n",
    "    print(f'type of pages_texts[0] is: {type(pages_texts[0])}') # str\n",
    "    print(f'len of pages_texts is: {len(pages_texts)}')\n",
    "    # print(f'the 12-th pages_texts is: {pages_texts[12]}')\n",
    "    return pages_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "568bafe8-1ff2-45c1-bc5c-945e30ced1a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of pages_texts is: <class 'list'>\n",
      "type of pages_texts[0] is: <class 'str'>\n",
      "len of pages_texts is: 2\n"
     ]
    }
   ],
   "source": [
    "pdf_path='./pdf_files/MSCS_handbook.pdf' # input your own pdf file\n",
    "\n",
    "pages_texts=upload_pdf(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43b022d3-38c2-4a8d-ae9c-7a22b72193e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_splitter(texts):\n",
    "    character_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=0\n",
    "    )\n",
    "    character_split_texts = character_splitter.split_text('\\n\\n'.join(texts))\n",
    "\n",
    "    token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "    token_split_texts = []\n",
    "    for text in character_split_texts:\n",
    "        token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "    return token_split_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2490292-b30d-42b9-b971-506c16f6e476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_split_texts=text_splitter(pages_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6686285a-0176-4a98-90dd-4deb16503fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(token_split_texts))\n",
    "print(type(token_split_texts))\n",
    "print(type(token_split_texts[0]))\n",
    "print(token_split_texts[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c7452-2991-40ca-8509-921e331ab35e",
   "metadata": {},
   "source": [
    "## add chunks into collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ba9b483-02fa-4b17-9316-e1c0ef43052c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6']\n"
     ]
    }
   ],
   "source": [
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "print(ids)\n",
    "coll_adapter.add(ids=ids, documents=token_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e023d29-1885-4bab-95f4-8afe2ceed9b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coll_adapter.get(ids=['0','3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e91755c3-2ec2-432f-8856-e35f7980e1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_adapter.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b42d2-3d61-41f6-9457-86fb2033ae6a",
   "metadata": {},
   "source": [
    "## Gemini API generate queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fca1660-e06e-45f7-b72b-51406ddedfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(): # \"role\": \"user\", don't use 'model'\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": \"You are a computer science advisor at a university. You help students with questions about course selection, graduation requirements, and majors to help them adjust to the university curriculum.\"\n",
    "\"Suggest 10 important short questions from the student handbook for the computer science major.\"\n",
    "\"Do not output any compound questions (questions that contain multiple sentences or conjunctions).\"\n",
    "\"Output each question on a separate line, separated by a line break.\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = model.generate_content(messages)\n",
    "    contents = response.text\n",
    "    # print('contents from augment_example_answer: \\n ', contents)\n",
    "    return response, contents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156babf2-e9da-4203-a5a7-706b2b441286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Google_API = input(\"Please input the Google Gemini API: \")\n",
    "genai.configure(api_key=Google_API)\n",
    "model = genai.GenerativeModel(model_name=\"gemini-pro\")\n",
    "\n",
    "response, generated_queries = generate_queries()\n",
    "# print(response)\n",
    "# print(generated_queries)\n",
    "# print(type(generated_queries)) # str\n",
    "\n",
    "generated_queries_arr=generated_queries.split('\\n')\n",
    "print(generated_queries_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b84628c-3a05-4b64-9ff5-82e827748a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print((len(generated_queries_arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00acf0f7-52e7-4fd5-958f-734901bde9ee",
   "metadata": {},
   "source": [
    "## coll_adapter.query queries the top-k results and obtains retrieved_documents and retrieved_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "638dc6b2-abf3-474a-9481-7f5713c01c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = coll_adapter.query(query_texts=generated_queries_arr, n_results=5, include=['documents', 'embeddings'])\n",
    "retrieved_documents = results['documents'] # 10*5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1cd52b0-3970-411c-b7e1-ea173105ffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "5\n",
      "project, but what you actually did. use the word “ i, ” not “ we ” when describing actions. result : describe the outcome of your actions and don ’ t be shy about taking credit for your behavior. what happened? how did the event end? what did you accomplish? what did you learn? make sure your answer contains multiple positive results. make sure that you follow all parts of the star method. be as specific as possible at all times, without rambling or including too much information. oftentim es students have to be prompted to include their results, so try to include that without being asked. also, eliminate any examples that do not paint you in a positive light. however, keep in mind that some exam ples that have a negative result ( such as “ lost the game ” ) can highlight your strengths in the face of adversity. sample star response : situation ( s ) : advertising revenue was falling o ff for my college newspaper, the review, and\n"
     ]
    }
   ],
   "source": [
    "print(len(retrieved_documents))\n",
    "print(len(retrieved_documents[0]))\n",
    "print(retrieved_documents[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543af94-4a39-43a1-86df-ccc06c303bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retrieved_embeddings = results['embeddings'] # 10*5*384\n",
    "print(len(retrieved_embeddings))\n",
    "print(len(retrieved_embeddings[0]))\n",
    "print(len(retrieved_embeddings[0][0]))\n",
    "\n",
    "print(retrieved_embeddings[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13a99fc-0920-4526-a918-7f2d8ac5c271",
   "metadata": {},
   "source": [
    "## Create labels and construct emb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "973204f3-0e27-4635-82bc-6c96246a721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(query, statement):\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": \"You are a computer science advisor at a university. You help students with questions about course selection, graduation requirements, and majors to help them adjust to the university curriculum.\"\n",
    "        \"For the given query, evaluate whether the following satement is relevant.\"\n",
    "        \"Output only 'yes' or 'no'.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": f\"Query: {query}, Statement: {statement}\"\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    response = model.generate_content(messages)\n",
    "    contents = response.text\n",
    "    if contents == \"yes\":\n",
    "        return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f413b63-c84f-4091-9ad7-88f893b6dd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "query_embeddings = emb_func(generated_queries_arr)\n",
    "\n",
    "print(len(query_embeddings))\n",
    "print(len(query_embeddings[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09adde59-77d7-40ab-90ee-4348d90c36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_query_embeddings = []\n",
    "adapter_doc_embeddings = []\n",
    "adapter_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4deb147b-c469-447e-8fbb-52f94b5aa34e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 1/10 [00:19<02:53, 19.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 2/10 [00:38<02:33, 19.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████▏                              | 3/10 [00:57<02:13, 19.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▌                          | 4/10 [01:16<01:55, 19.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████                      | 5/10 [01:35<01:35, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████▍                 | 6/10 [01:54<01:16, 19.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████▊             | 7/10 [02:13<00:57, 19.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████▏        | 8/10 [02:33<00:38, 19.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████▌    | 9/10 [02:52<00:19, 19.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [03:11<00:00, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "temp=1\n",
    "for q, query in enumerate(tqdm(generated_queries_arr)):\n",
    "    for d, document in enumerate(retrieved_documents[q]):\n",
    "        adapter_query_embeddings.append(query_embeddings[q])\n",
    "        adapter_doc_embeddings.append(retrieved_embeddings[q][d])\n",
    "        adapter_labels.append(evaluate_results(query, document))\n",
    "        time.sleep(3) # Don't access too quickly, otherwise: ResourceExhausted: 429 Resource has been exhausted (e.g. check quota).\n",
    "        print(temp)\n",
    "        temp+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0ae55715-8891-4312-8377-e975d53901c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "5\n",
      "50\n",
      "384\n",
      "50\n",
      "384\n",
      "50\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(generated_queries_arr)) # 10个相关query\n",
    "\n",
    "print(len(retrieved_embeddings)) # 10\n",
    "print(len(retrieved_embeddings[0])) # 每个query有5个相关results\n",
    "\n",
    "print(len(adapter_query_embeddings))\n",
    "print(len(adapter_query_embeddings[0]))\n",
    "\n",
    "print(len(adapter_doc_embeddings))\n",
    "print(len(adapter_doc_embeddings[0]))\n",
    "\n",
    "print(len(adapter_labels))\n",
    "print(adapter_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3b418001-f256-4572-8088-727d9fe8b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_query_embeddings = torch.Tensor(np.array(adapter_query_embeddings))\n",
    "adapter_doc_embeddings = torch.Tensor(np.array(adapter_doc_embeddings))\n",
    "adapter_labels = torch.Tensor(np.expand_dims(np.array(adapter_labels),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8a2549a2-8e9a-4efc-8801-0297e9f20956",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(adapter_query_embeddings, adapter_doc_embeddings, adapter_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0de2c9c1-50cc-4237-b92d-92c44dd45d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 384])\n",
      "torch.Size([50, 384])\n",
      "torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "print(adapter_query_embeddings.size())\n",
    "print(adapter_doc_embeddings.size())\n",
    "print(adapter_labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b085ecf-918a-4577-a53b-76d48ab6e113",
   "metadata": {},
   "source": [
    "## build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1b631f9d-ebc5-4cb8-8acc-e448c374ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(query_embedding, document_embedding, adaptor_matrix):\n",
    "#     print(f'query_embedding size: {query_embedding.size()}, document_emb size is {document_embedding.size()}, adaptor_matrix size is {adaptor_matrix.size()}')\n",
    "    updated_query_embedding = torch.matmul(adaptor_matrix, query_embedding)\n",
    "#     print(f'updated_query_embedding size is {updated_query_embedding.size()}')\n",
    "    return torch.cosine_similarity(updated_query_embedding, document_embedding, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8cb34a87-4b9c-4460-b542-378bd5172b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "torch.Size([384, 384])\n",
      "tensor(0.0314, grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "mat_size = len(adapter_query_embeddings[0])\n",
    "print(mat_size)\n",
    "\n",
    "adapter_matrix = torch.randn(mat_size, mat_size, requires_grad=True)\n",
    "print(adapter_matrix.size())\n",
    "\n",
    "# test the model output\n",
    "for query_embedding, document_embedding, label in dataset:\n",
    "    ans=model(query_embedding, document_embedding, adapter_matrix)\n",
    "    print(ans)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9679d5e3-09a1-4626-b7bd-c910b3ff3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(query_embedding, document_embedding, adaptor_matrix, label):\n",
    "# This cosine_similarity is used to calculate the loss. \n",
    "# If label=1, it means that the closer the similarity is to 1, the better. If label=0, it means that the closer the similarity is to 0, the better.\n",
    "    return torch.nn.MSELoss()(model(query_embedding, document_embedding, adaptor_matrix), label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "47db8171-3ad6-43cb-9815-0612d30779a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "torch.Size([384, 384])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the adaptor matrix\n",
    "mat_size = len(adapter_query_embeddings[0])\n",
    "print(mat_size)\n",
    "\n",
    "adapter_matrix = torch.randn(mat_size, mat_size, requires_grad=True)\n",
    "print(adapter_matrix.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603cec1-f59f-4e80-9190-c730d40356ae",
   "metadata": {},
   "source": [
    "If you want to do the training, first get the best_matrix and then assign it to the adapter_matrix, and then perform epoch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fd349358-bf5e-439d-831c-b7b5254a2799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4903,  0.2376, -0.6516,  ..., -1.7411, -0.6826,  0.8024],\n",
       "        [-0.3240, -0.3271, -1.4258,  ...,  1.7622,  0.4649,  2.0227],\n",
       "        [-0.2995,  1.0603,  0.9250,  ..., -0.7075, -1.2050, -0.8043],\n",
       "        ...,\n",
       "        [-0.7028, -2.2371,  1.6309,  ...,  0.6017,  0.0928, -0.8417],\n",
       "        [ 0.5026,  2.7048,  1.1416,  ..., -0.7423,  0.8264, -0.4187],\n",
       "        [ 0.8858, -0.2582, -1.2804,  ...,  2.4829,  1.4114, -0.2400]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_matrix = torch.from_numpy(best_matrix)\n",
    "adapter_matrix.requires_grad_(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3d26be69-4807-4888-91b5-3c58f192926d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [00:06<00:00, 80.72it/s]\n"
     ]
    }
   ],
   "source": [
    "min_loss = float('inf')\n",
    "best_matrix = None\n",
    "\n",
    "epoch_num=500\n",
    "for epoch in tqdm(range(epoch_num)):\n",
    "    for query_embedding, document_embedding, label in dataset:\n",
    "        loss = mse_loss(query_embedding, document_embedding, adapter_matrix, label)\n",
    "\n",
    "        if loss < min_loss:\n",
    "            min_loss = loss\n",
    "            best_matrix = adapter_matrix.clone().detach().numpy()\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            adapter_matrix -= 0.01 * adapter_matrix.grad\n",
    "            adapter_matrix.grad.zero_()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7965751a-cecd-4b12-9fb8-fe7c8a74a6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 0.6631836891174316\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best loss: {min_loss.detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "67f612dc-2cde-4687-9c2c-4eb9d73da4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "print(len(best_matrix))\n",
    "print(len(best_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4096fb9e-1c4e-4f99-a53d-9b60fde47125",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = torch.ones((mat_size,1))\n",
    "scaled_vector = np.matmul(best_matrix, test_vector).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1acaada7-327e-4b5b-a710-c4507ccaecce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(len(scaled_vector)), scaled_vector.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d993a9-7234-4402-9ee4-a5770d769ea2",
   "metadata": {},
   "source": [
    "\n",
    "## After training the adapter_matrix, the next step is:\n",
    "\n",
    "Now, input a query, and get the query_embedding vector through emb_func,  \n",
    "Then multiply the query_embedding and the adapter_matrix to get the updated_query_embedding vector,   \n",
    "Then use the updated_query_embedding vector to query the top-k most similar results using the chromadb query function (because of the adapter_matrix, the accuracy of the results found at this time is higher, that is, these k results are more related to the query text);  \n",
    "Input the query and results together into llm to get the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "74e5f224-12d0-4a41-8a98-6252a4c4ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " tell me more about registration.\n"
     ]
    }
   ],
   "source": [
    "query=input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f26d3ed0-1fcd-4012-aaa5-eaccf05d8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_matrix=best_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4a911663-3fc0-48dc-a264-052211852973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(384, 384)\n"
     ]
    }
   ],
   "source": [
    "print(type(adapter_matrix))\n",
    "print(adapter_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fffea17a-0152-4f87-ad8c-1f8ea64acbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "query_embedding=emb_func([query]) # Do not enter emb_func(query) directly, otherwise a 1*384 vector will be generated for each character.\n",
    "print(len(query_embedding))\n",
    "print(len(query_embedding[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1326fba0-8d05-485b-9a3f-7ac372ba546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n"
     ]
    }
   ],
   "source": [
    "query_embedding_np = np.array(query_embedding)\n",
    "print(query_embedding_np.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e838d6dd-3afb-49d9-9bcb-8d34f65bde63",
   "metadata": {},
   "source": [
    "## Query_emb and adapter_matrix matrix multiplication\n",
    "note that it is np multiplication, format conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2caed83c-1680-4adf-aa9b-ce24f06c27c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(384, 1)\n"
     ]
    }
   ],
   "source": [
    "updated_query_emb_np = np.matmul(adapter_matrix, query_embedding_np.T)\n",
    "\n",
    "print(type(updated_query_emb_np))\n",
    "print(updated_query_emb_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8c89979d-d87b-4833-8556-2bb609a05082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "1\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "updated_query_emb=updated_query_emb_np.T.tolist() \n",
    "# Note that it is a 2-layer array, and both the inner and outer layers need to be converted from np to list\n",
    "\n",
    "print(type(updated_query_emb))\n",
    "print(type(updated_query_emb[0]))\n",
    "print(len(updated_query_emb))\n",
    "print(len(updated_query_emb[0]))\n",
    "\n",
    "# print(updated_query_emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "156ed3a0-9f5a-460f-8111-e463cfc3def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = coll_adapter.query(query_embeddings=updated_query_emb, n_results=5, include=['documents', 'embeddings'])\n",
    "\n",
    "results_original=coll_adapter.query(query_texts=query, n_results=5, include=['documents', 'embeddings'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e75643ed-4986-47e7-bf3b-a2161d38f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_doc=results['documents']\n",
    "results_emb=results['embeddings']\n",
    "\n",
    "results_doc_original=results_original['documents']\n",
    "results_emb_original=results_original['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d8682fa1-aeba-4098-a949-422d7f525249",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "1\n",
      "5\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "print(len(results_doc))\n",
    "print(len(results_doc[0]))\n",
    "# print(results_doc[0])\n",
    "\n",
    "print(len(results_emb))\n",
    "print(len(results_emb[0]))\n",
    "print(len(results_emb[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "421dda2a-b18c-4840-aef9-70400fa2151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "information = \"\\n\\n\".join(results_doc[0])\n",
    "information_original = \"\\n\\n\".join(results_doc_original[0])\n",
    "# print(information)\n",
    "def get_answer(query, information):\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": \"You are a computer science advisor at a university. You help students with questions about course selection, graduation requirements, and majors to help them adjust to the university curriculum.\"\n",
    "        \"I have given you some relevant information. Please answer the question.\"    \n",
    "    },\n",
    "     {\"role\": \"user\", \"parts\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "\n",
    "    response = model.generate_content(messages)\n",
    "    contents = response.text\n",
    "    return contents\n",
    "\n",
    "Google_API = input(\"Please input the Google Gemini API: \")\n",
    "# print(Google_API)\n",
    "genai.configure(api_key=Google_API)\n",
    "model = genai.GenerativeModel(model_name=\"gemini-pro\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4626f705-4aaa-4e98-858e-3953f41ca0aa",
   "metadata": {},
   "source": [
    "## Comparing the effects before and after using the adapter\n",
    "\n",
    "I found that the effects were not good. . .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "062fd935-aebb-4731-8dc5-42023d732928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but the information you have provided does not include any details about registration.\n"
     ]
    }
   ],
   "source": [
    "answer=get_answer(query, information)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "24c5135d-11a9-4a39-9139-3be5fda873e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry, but the information you provided does not contain any information about registration.\n"
     ]
    }
   ],
   "source": [
    "answer_original=get_answer(query, information_original)\n",
    "print(answer_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93bd010-6f18-4cbd-b2cb-14145bace531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(information)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5e6e32-e476-48f3-ae68-25705ccd35bd",
   "metadata": {},
   "source": [
    "## Combining query expansion method and embedding adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b8470516-2ca5-45b8-bddf-0ffb9449c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_multiple_query(query): \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"model\",\n",
    "            \"parts\": \"You are a computer science advisor at a university. You help students with questions about course selection, graduation requirements, and majors to help them adjust to the university curriculum.\"\n",
    "                    \"Generate 5 important related short questions based on the the question given to you.\"\n",
    "                    \"Do not output any compound questions (questions that contain multiple sentences or conjunctions).\"\n",
    "                    \"Output each question on a separate line, separated by a line break.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"parts\": f\"Question: {query}\"}\n",
    "    ]\n",
    "\n",
    "    response = model.generate_content(messages)\n",
    "    contents = response.text\n",
    "    # print('contents from augment_example_answer: \\n ', contents)\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "bdf7b9ec-7a90-4a68-bc11-9e71fb5b9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_example_answer(query):\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"model\",\n",
    "            \"parts\": \"You are a computer science advisor at a university. You help students with questions about course selection, graduation requirements, and majors to help them adjust to the university curriculum.\"\n",
    "            \"Provide an example answer to the given question, that might be found in a document like a student MSCS Handbook. \"\n",
    "        },\n",
    "        {\"role\": \"user\", \"parts\":  f\"Question: {query}\"}\n",
    "    ]\n",
    "\n",
    "    response = model.generate_content(messages)\n",
    "    contents = response.text\n",
    "    # print('contents from augment_example_answer: \\n ', contents)\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "60e3f0d3-6ea3-4d3b-abee-a08702c7b5f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tell me more about registration.\n",
      "the original question is: tell me more about registration., \n",
      " and the related short questions are: - What are the dates for the next registration period?\n",
      "- How do I create a registration plan?\n",
      "- Can you help me interpret my registration status?\n",
      "- What is the difference between a hold and a block?\n",
      "- How can I change my registration after I have submitted it?, \n",
      " the hypothetical answer is: **Registration**\n",
      "\n",
      "Registration is the process of selecting the courses you will take for the upcoming semester. It is important to choose courses that fulfill your graduation requirements and align with your interests.\n",
      "\n",
      "**Steps for Registering**\n",
      "\n",
      "1. **Check your registration time:** Your registration time will be assigned based on your academic standing and major. You can find your registration time on your student portal.\n",
      "2. **Meet with your advisor:** Before registering, it is recommended to meet with your advisor to discuss course selection and create a plan for your semester.\n",
      "3. **Select courses:** Utilize the course catalog to browse course offerings and select the courses you wish to take.\n",
      "4. **Build your schedule:** Create a schedule that aligns with your availability and includes all necessary courses.\n",
      "5. **Register:** Register for your selected courses through the student portal.\n",
      "\n",
      "**Course Load**\n",
      "\n",
      "The typical course load for full-time graduate students is 9-12 credit hours per semester. However, you may adjust your course load based on your academic progress and personal circumstances.\n",
      "\n",
      "**Add/Drop Courses**\n",
      "\n",
      "During the first few weeks of the semester, you may add or drop courses as needed. To add a course, visit the registrar's office. To drop a course, complete the course drop form and submit it to the registrar.\n",
      "\n",
      "**Registration Deadlines**\n",
      "\n",
      "It is important to meet all registration deadlines to avoid late fees or course availability issues. Check the academic calendar for specific deadlines.\n",
      "\n",
      "**Registration Tips**\n",
      "\n",
      "* Register as early as possible to secure your desired courses.\n",
      "* Prioritize courses that are required for your major and fulfill graduation requirements.\n",
      "* Consider your availability and extracurricular commitments when building your schedule.\n",
      "* Seek assistance from your advisor or the registrar's office if you have any questions or require additional support.\n"
     ]
    }
   ],
   "source": [
    "print(query)\n",
    "hypothetical_answer = augment_example_answer(query)\n",
    "augmented_queries = augment_multiple_query(query)\n",
    "\n",
    "joint_query = f\"the original question is: {query}, \\n and the related short questions are: {augmented_queries}, \\n the hypothetical answer is: {hypothetical_answer}\"\n",
    "\n",
    "print(joint_query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9dca4e40-eac8-4873-9ffe-8d5f99ef1d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "['- What are the dates for the next registration period?', '- How do I create a registration plan?', '- Can you help me interpret my registration status?', '- What is the difference between a hold and a block?', '- How can I change my registration after I have submitted it?']\n"
     ]
    }
   ],
   "source": [
    "print(type(augmented_queries))\n",
    "augmented_queries_arr=augmented_queries.split('\\n')\n",
    "print(augmented_queries_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37118de8-7b0e-4cc3-860b-b35679193597",
   "metadata": {},
   "source": [
    "\n",
    "Because the hypothetical answer is very long, and the related questions are very short.  \n",
    "You can input the original question and related questions as a list jointed_query to chromadb to find information,  \n",
    "and then give the final answer based on the jointed_query+information+hypothetical_answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "696f6a80-3136-4006-ad67-07ef8e298ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "jointed_query=[query]+augmented_queries_arr\n",
    "print(len(jointed_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5d03e68f-1784-4f8c-9f29-ed8ba8c622d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "jointed_query_emb = emb_func(jointed_query)\n",
    "print(len(jointed_query_emb))\n",
    "print(len(jointed_query_emb[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df13727-4e31-45b3-bb38-0e64ae315e14",
   "metadata": {},
   "source": [
    "## Convert jointed_query_emb to np and multiply it with adapter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b3dfd18b-76b8-4da8-a4da-2807b092cc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 384)\n"
     ]
    }
   ],
   "source": [
    "jointed_query_emb_np = np.array(jointed_query_emb)\n",
    "print(jointed_query_emb_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f6ff8698-338d-4c21-af6d-1ad7a9cc2e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "updated_jointed_query_emb_np = np.matmul(adapter_matrix, jointed_query_emb_np.T)\n",
    "\n",
    "updated_jointed_query_emb=updated_jointed_query_emb_np.T.tolist() # 注意是2层array，需要内外层都从np转为list\n",
    "\n",
    "print(len(updated_jointed_query_emb))\n",
    "print(len(updated_jointed_query_emb[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fa91f92a-d124-4788-b3ef-c29eacd74817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return early and to confirm their academics will not be negatively impacted going forward. for a full review of georgia tech ’ s withdrawal policy, please review the registrar ’ s office page for withdrawal and dropping courses. leave of absence / application to return students may have extenuating circumstances that require them to miss multiple semesters ( e. g. military service ). in this instance, a student can apply to take a leave of absence. the student will submit an application to request a leave of absence and, if approved, eventually an “ application to return ” once the student is ready to return to georgia tech. the office of the registrar is responsible for reviewing and approving leave of absence applications. for a full review of the leave of absence policy, steps to take, and access to appropriate applications - please review the registrar ’ s office leave of absence page.\n",
      "\n",
      "15 international students – withdrawing from a course while withdrawing from a course can certainly allow a student to preserve their gpa, it can potentially have a negative impact on international students ’ visa eligibility. for example, full - time status is required for international students – actively attending at least 12 hours of coursework. if an international student takes only 12 hours and withdraws from a 3 - hour course, the student would be in violation of f1 / j1 enrollment requirement s as they would no longer be actively full - time. there are specific policies and procedures that may allow an international student to attend below full - time which may be found on oie ’ s enrollment requirements page. • summer terms • academic reduced course loads • medical reduced course loads academic reduced course loads an international student that is required to maintain full - time status may seek a n academic reduced\n",
      "\n",
      "… … … … … … … … … … … … … … … … … … … … … … …. …. … …. 15 academic reduced course loads … … … … … … … … … … … … … … … … … … … … … … … … … … … … … … … … … … … … …. … … …. 15\n",
      "\n",
      "the course on a student ’ s transcript, indicating the student initially attempted the course but needed to withdraw. a “ w ” has no impact on one ’ s gpa. for step - by - step instructions on how to drop / withdraw from a course, please visit the registrar office ’ s withdrawal and dropping courses page. if a student drops or withdraws from a course, they should check their schedule afterwards to confirm the change was processed. • if a student withdraws from all courses during the term, this is referred to as a “ full withdrawal. ” the student may be eligible for a partial refund as a result. please refer to the bursar office ’ s refund calendar for more information. • if a student is still active in at least one course after withdrawing, they would not be eligible to receive a refund. * * * a “ full withdrawal ” does not mean a student is dropped or ineligible from the mscs program. it simply means the student withdrew from all of their courses for the term. * * *\n",
      "\n",
      "9 631 cherry street, room 301 atlanta, ga, 30332 - 0321 o if an institution releases official transcripts electronically, please send them to transcripts @ grad. gatech. edu – transcripts must come directly from the institution, not the student. • lawful presence hold – only the documents listed on graduate education's lawful presence page can be used to clear this hold. for questions, please contact grad. ask @ grad. gatech. edu. • immunization hold – if students have any questions regarding this hold, they should contact immunizations @ health. gatech. edu or 404 - 894 - 1432. • financial agreement hold – a financial agreement hold is initially placed on all students ’ accounts. this hold will prevent registration ; however, students can clear the hold immediately in oscar prior to their registration period. on the registration menu, select “ financial responsibility agreement ”. after reading and understanding the\n"
     ]
    }
   ],
   "source": [
    "results_jointed = coll_adapter.query(query_embeddings=updated_jointed_query_emb, n_results=5, include=['documents'])\n",
    "results_jointed_doc=results['documents']\n",
    "\n",
    "information_jointed = \"\\n\\n\".join(results_jointed_doc[0])\n",
    "\n",
    "print(information_jointed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "12b2c1e2-816c-4ecf-87f6-a8200fc1b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_jointed(original_query, related_query, hypothetical_ans, information):\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": \"You are a computer science advisor at a university. You help students with questions about course selection, graduation requirements, and majors to help them adjust to the university curriculum.\"\n",
    "        \"I have given you Related Questions related to the Original Question, the Hypothetical Answer of the Original Question, and some Reference Information. Please answer the Original Question.\"    \n",
    "    },\n",
    "     {\n",
    "         \"role\": \"user\", \n",
    "         \"parts\": f\"Original Question: {original_query}. \\n Related Questions:{related_query}. \\n Hypothetical Answer: {hypothetical_ans}. \\n Reference Information: {information}\"\n",
    "     }\n",
    "    ]\n",
    "\n",
    "    response = model.generate_content(messages)\n",
    "    contents = response.text\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "727ab6a8-fe43-4f0b-8bea-ef7c10a11915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Google_API = input(\"Please input the Google Gemini API: \")\n",
    "# print(Google_API)\n",
    "\n",
    "genai.configure(api_key=Google_API)\n",
    "model = genai.GenerativeModel(model_name=\"gemini-pro\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "07b03dc6-2f32-42e6-a2f7-73cdc29d4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=get_answer_jointed(query,augmented_queries,hypothetical_answer,information_jointed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9dad27ff-3ba0-4f04-a4b6-d3fc6e5d268b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Registration** is the process of selecting and enrolling in courses for a semester. Here's a brief overview:\n",
      "\n",
      "**Steps:**\n",
      "\n",
      "1. **Check registration dates:** Determine the designated registration period for your academic level and major.\n",
      "2. **Meet with your advisor:** Discuss your course selections, graduation requirements, and major-specific recommendations.\n",
      "3. **Select courses:** Browse the course catalog and choose courses that align with your program and interests.\n",
      "4. **Build a schedule:** Create a schedule that accommodates your availability and course requirements.\n",
      "5. **Register:** Input your course selections through the university's online registration system or meet with a registration representative.\n",
      "\n",
      "**Course Load:**\n",
      "\n",
      "Full-time graduate students typically carry 9-12 credit hours per semester, but this may vary depending on your progress and circumstances.\n",
      "\n",
      "**Add/Drop Courses:**\n",
      "\n",
      "During the first few weeks of the semester, you may adjust your schedule by adding or dropping courses. Consult with the registrar's office for specific guidelines.\n",
      "\n",
      "**Registration Deadlines:**\n",
      "\n",
      "Meet all registration deadlines to avoid late fees or course availability issues. Check the academic calendar for specific dates.\n",
      "\n",
      "**Tips:**\n",
      "\n",
      "* Register early to secure desired courses.\n",
      "* Prioritize courses required for your major and graduation.\n",
      "* Consider your schedule and extracurricular commitments.\n",
      "* Seek assistance from your advisor or the registrar's office if needed.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
