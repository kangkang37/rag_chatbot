{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0ee0193-da15-4e09-897b-acec5c733c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gradio as gr\n",
    "import time\n",
    "from pypdf import PdfReader\n",
    "import google.generativeai as genai\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d59f29-53f8-45c1-abef-1e65c8a54a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_read_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    pdf_texts = [p.extract_text().strip() for p in reader.pages]  # length of pdf_texts is the number of pages of upload pdf.\n",
    "    pdf_texts = [text for text in pdf_texts if text]\n",
    "    \n",
    "    print (f\"the pdf text length: {len(pdf_texts)}, '\\n', the content of pdf_texts[0]: {pdf_texts[0][:100]}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    # text splitter\n",
    "    character_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=0\n",
    "    )\n",
    "    character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "    print(f\"Character split into {len(character_split_texts)} chunks.\")\n",
    "\n",
    "    token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "    token_split_texts = [token_split for text in character_split_texts for token_split in token_splitter.split_text(text)]\n",
    "    print(f\"Token split into {len(token_split_texts)} chunks.\")\n",
    "\n",
    "    print('the following are the chunks from this upload pdf: ')\n",
    "    for i in range(len(token_split_texts)):\n",
    "        print(token_split_texts[i])\n",
    "        print('\\n')\n",
    "        \n",
    "    return token_split_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fbec3d9-a220-4d6f-91e5-5c8a2000aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment_example_answer(query):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"model\",\n",
    "            \"parts\": \"I have gived you a query about resume pdf files. Provide an example answer to the given question, that might be found in a document like a resume. \"\n",
    "        },\n",
    "        {\"role\": \"user\", \"parts\": query}\n",
    "    ] \n",
    "\n",
    "    response = model.generate_content(messages)\n",
    "    contents = response.text\n",
    "    # print('contents from augment_example_answer: \\n ', contents)\n",
    "    \n",
    "    # response = openai_client.chat.completions.create(\n",
    "    #     model=model,\n",
    "    #     messages=messages,\n",
    "    # )\n",
    "    # contents = response.choices[0].message.content\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94aeec5a-5cad-4b72-9d9f-11340e810b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment_multiple_query(query):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"model\",\n",
    "            \"parts\": \"You are an experienced recruiter. Your users are asking questions about resumes. \"\n",
    "            \"Suggest up to five additional related questions to help them find the information they need, for the provided question. \"\n",
    "            \"Suggest only short questions without compound sentences. Suggest a variety of questions that cover different aspects of the topic.\"\n",
    "            \"Make sure they are complete questions, and that they are related to the original question.\"\n",
    "            \"Output one question per line. Do not number the questions.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"parts\": query}\n",
    "    ]\n",
    "\n",
    "    response = model.generate_content(messages)\n",
    "    contents = response.text\n",
    "    # print('contents from augment_multiple_query: ', contents)\n",
    "    contents = contents.split(\"\\n\") # return list\n",
    "    \n",
    "    # response = openai_client.chat.completions.create(\n",
    "    #     model=model,\n",
    "    #     messages=messages,\n",
    "    # )\n",
    "    # content = response.choices[0].message.content\n",
    "    # contents = content.split(\"\\n\")\n",
    "    return contents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecbb9d5b-a768-4f32-8466-d37f30975bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(message, history):\n",
    "    \n",
    "    text_message = message['text']  # get text from message\n",
    "    file_paths = message['files']\n",
    "    num_files = len(file_paths)\n",
    "\n",
    "    yield f\"You uploaded {num_files} files, the message is: {message}.\"\n",
    "    time.sleep(1)\n",
    "    if not chroma_collection.get()['ids'] and not message['files']:  # 没有上传file，并且chroma没有存储之前上传的pdf\n",
    "        yield f'there are no data in chroma collection. \\n {chroma_collection.get()}, and no upload pdf!'\n",
    "        return\n",
    "\n",
    "    print('the ids of chroma_collection: ', chroma_collection.get()['ids'])\n",
    "\n",
    "    # read the first file\n",
    "    # if upload file from message:\n",
    "    if message['files']:\n",
    "        pdf_path = file_paths[0]\n",
    "\n",
    "        token_split_texts = helper_read_pdf(pdf_path)\n",
    "        \n",
    "        # reader = PdfReader(pdf_path)\n",
    "        # pdf_texts = [p.extract_text().strip() for p in\n",
    "        #              reader.pages]  # length of pdf_texts is the number of pages of upload pdf.\n",
    "        # pdf_texts = [text for text in pdf_texts if text]\n",
    "        # yield f\"the pdf text length: {len(pdf_texts)}, '\\n', the content of pdf_texts[0]: {pdf_texts[0][:100]}\"\n",
    "        # time.sleep(1)\n",
    "\n",
    "        # # text splitter\n",
    "        # character_splitter = RecursiveCharacterTextSplitter(\n",
    "        #     separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        #     chunk_size=1000,\n",
    "        #     chunk_overlap=0\n",
    "        # )\n",
    "        # character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "        # print(f\"Character split into {len(character_split_texts)} chunks.\")\n",
    "\n",
    "        # token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "        # token_split_texts = [token_split for text in character_split_texts for token_split in\n",
    "        #                      token_splitter.split_text(text)]\n",
    "        # print(f\"Token split into {len(token_split_texts)} chunks.\")\n",
    "\n",
    "        max_id = max(map(int, chroma_collection.get()['ids']), default=0)\n",
    "        ids = [str(i) for i in range(max_id + 1, max_id + 1 + len(token_split_texts))]\n",
    "        chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "        print(f\"Added {len(ids)} chunks to Chroma collection.\")\n",
    "\n",
    "    ids_str = str(chroma_collection.get()['ids']) # get all ids from collection\n",
    "\n",
    "    original_query = text_message\n",
    "\n",
    "    # method 1: get hypothetical answer from the original query\n",
    "    hypothetical_answer = augment_example_answer(original_query) # get example answer\n",
    "    print('\\n hypothetical answer: ', hypothetical_answer)\n",
    "    \n",
    "    joint_query = f\"{original_query} {hypothetical_answer}\"\n",
    "    ##\n",
    "\n",
    "    # method 2: get multi-querys from original query\n",
    "    augmented_queries = augment_multiple_query(original_query)\n",
    "    print('\\n multi_querys: ', augmented_queries)\n",
    "\n",
    "    joint_query = [original_query] + augmented_queries\n",
    "    ##\n",
    "    \n",
    "    results = chroma_collection.query(query_texts=joint_query, n_results=5)\n",
    "    # print(results)\n",
    "    \n",
    "    # results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "    retrieved_documents = results['documents'][0]\n",
    "\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "    # information = pdf_texts\n",
    "\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"model\",\n",
    "            \"parts\": \"answer the question based on the information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"parts\": f\"Question: {original_query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "    response = model.generate_content(prompt)\n",
    "    contents = response.text\n",
    "    yield f\"the ids_str: {ids_str},\\n the original_query is: {original_query}, \\n the information is: {information}, \\n\\n the contents: {contents}\"\n",
    "    # time.sleep(3)\n",
    "    # yield contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d25e48a-7fb5-4527-8b89-d06359146a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collections(coll_name):\n",
    "    embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "    chroma_client = chromadb.Client()\n",
    "    \n",
    "    collections = chroma_client.list_collections()\n",
    "    collection_names = [collection.name for collection in collections]\n",
    "\n",
    "    # if coll_name not exist in the collection_names\n",
    "    if coll_name not in collection_names:\n",
    "        chroma_coll = chroma_client.create_collection(coll_name, embedding_function=embedding_function)\n",
    "        print(f\"Collection {coll_name} created.\")\n",
    "    else: # already exists this collection\n",
    "        chroma_coll = chroma_client.get_collection(coll_name)\n",
    "        print(f\"Collection {coll_name} already exists.\")\n",
    "\n",
    "    return chroma_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4412f-6530-4ab0-b0fd-219ba4bdba38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f64b28bf-9b83-418d-a7b2-2aeed8943d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection test1 already exists.\n",
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the ids of chroma_collection:  ['1', '2', '3', '4', '5', '6', '7']\n",
      "\n",
      " hypothetical answer:  **Example Answer:**\n",
      "\n",
      "**Objective:**\n",
      "\n",
      "Seeking a challenging and rewarding position in the field of [field] where I can utilize my [skills] and [experience] to contribute to the success of the organization.\n",
      "\n",
      "**Skills:**\n",
      "\n",
      "* [Skill 1]\n",
      "* [Skill 2]\n",
      "* [Skill 3]\n",
      "\n",
      "**Experience:**\n",
      "\n",
      "**Position**, [Company Name], [Dates]\n",
      "\n",
      "* [Responsibility 1]\n",
      "* [Responsibility 2]\n",
      "* [Responsibility 3]\n",
      "\n",
      "**Education:**\n",
      "\n",
      "**Degree**, [University Name], [Dates]\n",
      "\n",
      "**Certifications:**\n",
      "\n",
      "* [Certification 1]\n",
      "* [Certification 2]\n",
      "\n",
      "**Awards and Recognition:**\n",
      "\n",
      "* [Award 1]\n",
      "* [Award 2]\n",
      "\n",
      "**References:**\n",
      "\n",
      "Available upon request.\n",
      "\n",
      " multi_querys:  ['- What are the most important sections to include on a resume?', '- How long should a resume be?', '- What is the best font to use for a resume?', '- Should I include a photo on my resume?', '- What are some common mistakes to avoid when writing a resume?']\n",
      "the ids of chroma_collection:  ['1', '2', '3', '4', '5', '6', '7']\n",
      "the pdf text length: 1, '\n",
      "', the content of pdf_texts[0]: Kangyi Qiu\n",
      "/envel⌢pekqiu37@gatech.edu ♂phone404-436-9016 /linkedinlinkedin.com/kangyi-qiu\n",
      "Education\n",
      "\n",
      "Character split into 5 chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kangyiqiu/miniconda3/envs/rag/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token split into 5 chunks.\n",
      "the following are the chunks from this upload pdf: \n",
      "kangyi qiu / [UNK] @ gatech. edu [UNK] - 436 - 9016 / linkedinlinkedin. com / kangyi - qiu education georgia institute of technology, college of computing aug 2022 - dec 2024 master of computer science, school of computer science atlanta, ga peking university, school of electronics engineering and computer science sep 2018 - july 2022 bachelor of science, major in machine intelligence beijing, china relevant coursework : computational science & engineering algorithms, artiﬁcial intelligence, data & visual analytics, introduction to computer systems, the brain and cognitive science, computer vision and deep learning. work experience sony china co., ltd. research center jul. 2023 – nov. 2023 computer vision intern beijing, china • trained person re - identiﬁcation ( reid ) model based on resnet using the momentum contrast ( moco ) method with the pass and imagenet datasets, leveraging python and tensorflow 2. 0.\n",
      "\n",
      "\n",
      "• compared the pre - training performance between pass and imagenet by evaluating the classiﬁcation accuracy on the validation dataset, with the pass dataset demonstrating similar downstream performance to imagenet. • implemented the unsupervised learning method moco and conducted an analysis of the strengths and weaknesses of its three versions ( v1 / v2 / v3 ) in terms of data augmentation and model structure. project experience multimodal large language model ( mllm ) application based on rag jan. 2024 - may 2024 • achieved multimodal any - to - any search by encoding data into a shared semantic embedding space via contrastive learning, facilitating the construction of a multimodal recommender system. • improved language generation models through the integration of multimodal retrieval augmented generation ( mm - rag ). models enhanced with retrieval produce signiﬁcantly more coherent, grounded, and speciﬁc outputs. animal breed identiﬁcation project based on vit model oct. 2023 - dec. 2023\n",
      "\n",
      "\n",
      "• developed a vision transformer ( vit ) network to achieve classiﬁcation prediction of dog species using python and pytorch. the ﬁne - tuning dataset consists of 10, 222 images across 120 [UNK] classiﬁcations. • improved the prediction accuracy from 88. 4 % to 91. 2 % by data augmentation and regularization, model optimization, and parameter ﬁne - tuning, etc, avoiding the model over - ﬁtting and gradient vanishing problems. • developed a web application for this model, utilizing the flask framework and python to construct the back - end server, and designed the front - end interface using html, css, and javascript. text - to - image generation based on [UNK] model apr. 2023 - jul. 2023 • designed, trained and optimized a [UNK] model for text - to - image generation using the fashion - mnist dataset and mnist dataset with pytorch. the datasets consist of 10 categories and use small - size training images.\n",
      "\n",
      "\n",
      "• adjusted model parameters, structure, and training times, and experimented with various optimizers and loss functions to compare model performance under [UNK] conditions. • design a user - friendly web interface using the gradio library to showcase model functionalities, including image transmission and display, hyperparameter adjustment, prompt input, and switching of training datasets. ai snake training based on reinforcement learning ( rl ) feb. 2023 - may 2023 • constructed a neural network incorporating reward and punishment mechanisms, enabling the snake to learn score - maximizing strategies through interactions with the environment. • utilized bayesian optimization to discover the optimal combination of hyperparameters for neural networks. research experience reserach on the processing - in - memory mar. 2021 - mar. 2022 • published a paper titled ” heterogeneous memory architecture accommodating processing - in - memory on soc for\n",
      "\n",
      "\n",
      "aiot applications ” as the ﬁrst author at the 27th asia and south paciﬁc design automation conference in 2022. • proposed the heterogeneous memory architecture ( hma ) and a tensor mapping approach aimed at reducing data transfer costs and accelerating data calculations of general matrix multiplication ( gemm ). technical skills languages & databases : python ( pytorch, tensorﬂow2. 0 ), java, c + +, html, css, javascript, flask, mysql.\n",
      "\n",
      "\n",
      "Added 5 chunks to Chroma collection.\n",
      "\n",
      " hypothetical answer:  This applicant does not have rich internship and project experience. They only mention one internship experience and one project experience. The internship experience was as a Marketing Intern, and the project experience was a personal project to develop a mobile app. The applicant does not provide a lot of detail about either experience, so it is difficult to assess their skills and abilities. Overall, this applicant does not have a lot of experience to draw from, which could be a concern for potential employers.\n",
      "\n",
      " multi_querys:  [\"What are the key factors to consider when evaluating an applicant's experience?\", 'Have they demonstrated leadership or teamwork skills in their internships and projects?', 'Are their projects aligned with the requirements of the role they are applying for?', 'What are the most common mistakes applicants make when describing their experience on their resume?', \"Are there any specific industry-related or technical skills that you are looking for in this applicant's experience?\"]\n",
      "the ids of chroma_collection:  ['1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "\n",
      " hypothetical answer:  **Example Answer:**\n",
      "\n",
      "**Relevant Experience**\n",
      "\n",
      "**Software Engineer**, ABC Tech Solutions, 2019 - Present\n",
      "\n",
      "* Developed and maintained enterprise software solutions using Java, Python, and C++\n",
      "* Led a team of engineers in the implementation of a cloud-based data analytics platform\n",
      "* Optimized system performance and resolved critical issues, reducing downtimes by 50%\n",
      "\n",
      "**Software Developer**, XYZ Corporation, 2017 - 2019\n",
      "\n",
      "* Designed and implemented web applications using Agile methodologies\n",
      "* Implemented RESTful APIs for seamless data integration and interoperability\n",
      "* Participated in the design and development of a mobile app, increasing user engagement by 20%\n",
      "\n",
      "**Education**\n",
      "\n",
      "**Master of Science in Computer Science**, University of California, Berkeley, 2016\n",
      "\n",
      "**Bachelor of Science in Computer Engineering**, Stanford University, 2014\n",
      "\n",
      "**Skills**\n",
      "\n",
      "* Programming Languages: Java, Python, C++, HTML, CSS\n",
      "* Software Development Methodologies: Agile, Scrum, Kanban\n",
      "* Cloud Computing: AWS, Azure, GCP\n",
      "* Data Analytics: SQL, NoSQL, Hadoop\n",
      "* Communication: Excellent written and verbal communication skills\n",
      "\n",
      " multi_querys:  ['Are there any resume templates available?', 'Can I use a resume builder to create my resume?', 'What are the most important sections to include in a resume?', 'Is it okay to include a photo on my resume?', 'What are some tips for writing a strong resume summary?']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    Google_API = \"AIzaSyBvTMTgsk9jF5oCbdMBiEUfPEl5F2dZM68\"\n",
    "    genai.configure(api_key=Google_API)\n",
    "\n",
    "    # chroma\n",
    "    collection_name = \"test1\"\n",
    "    chroma_collection = create_collections(collection_name)\n",
    "\n",
    "    model = genai.GenerativeModel(model_name=\"gemini-pro\")\n",
    "\n",
    "    demo = gr.ChatInterface(fn=count_files, examples=[{\"text\": \"Hello\", \"files\": []}], title=\"RAG Chat Bot\",\n",
    "                            multimodal=True)\n",
    "\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ff1eb-2526-4f78-a4b3-cb6eae3f4186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
